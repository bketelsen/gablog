Go Advent Day 2 - Go 1.2 performance improvements
2 Dec 2013
Tags: goadvent

Dave Cheney

* Introduction

7 months, 1600 changes, well over 350 issues closed¹, and [[http://blog.golang.org/go12][Go 1.2 is done]].

Go and install it now, its ok, it only takes a few minutes, I'll wait.

When Go 1.1 was released earlier in the year I did a series of posts ([[http://dave.cheney.net/2013/05/21/go-11-performance-improvements][part 1]], [[http://dave.cheney.net/2013/05/25/go-11-performance-improvements-part-2][part 2]], [[http://dave.cheney.net/2013/05/28/go-11-performance-improvements-part-3][part 3]]) exploring the performance improvements the then current released provided. Go 1.1 was a herculean development effort, stretching some 14 months and bought with it equally impressive performance improvements.

This time around Go 1.2 was a 7 month development effort with a fixed delivery date announced up front. Contributors spent 3-4 months landing improvements before a 3 month feature freeze. 

Of course, shorter cycles mean less scope for performance improvement, but as we shall discover, Go 1.2 has not failed to deliver.

¹ [[https://code.google.com/p/go/issues/list?can=1&q=label%3Ago1.2+OR+label%3Ago1.2maybe+AND+status%3AFixed+&colspec=ID+Status+Stars+Priority+Owner+Reporter+Summary&cells=tiles][Go 1.2 Closed issues]] -- the real number is probably higher, many issues are closed without being tagged for the release they are fixed in.

* The top line number

A widely quoted figure for the Go 1.1 performance improvements was [[http://golang.org/doc/go1.1#performance][30-40%]]. As Go matures it becomes harder to find these big performance gains, and is just as difficult to summarize them in a single sentence. To find out more, read on.

* Performance headlines

This next section highlights some of the major performance improvements that landed in Go 1.2.

** 8kb stack segments

Since the earliest days of Go, each goroutine has allocated stack segments in units of 4096 bytes. Being equal to the operating system page size made this a sensible default, but it had been known for some time that code which was recursive or contained inner loops of long call chains (most of the `encoding/*` packages fall into this category) stack splitting, or stack straddling was a significant cause of slowdown, and benchmark instability. 

In October Russ Cox proposed doubling this value to 8k and [[https://codereview.appspot.com/14317043/][presented a detailed analysis]] to support this change. This one change alone boosted many of the Go 1 benchmarks by 10% alone, but the main clue that this was the right decision was the infamously unreliable `JsonEncoder` benchmark became stable and predictable.

Russ' data demonstrated that the original 4k stack size was wrong, and as it had been chosen without empirical evidence, a number which could not be defended. However increasing the granularity of by which goroutines allocate memory from the operating system has a cost. The trade offs of this change are discussed in the final section of this article.

.image day-02-go-1.2-performance-improvements/go1-amd64.png
.image day-02-go-1.2-performance-improvements/go1-386.png
.image day-02-go-1.2-performance-improvements/go1-arm.png

** Preemption

Prior to Go 1.2 a single goroutine could hog the entire CPU if it ran in a tight loop. The effect of this CPU hogging is well known for programs which run with the default value of `GOMAXPROCS` but it has a more subtle effect on garbage collection performance.

When a garbage collection cycle is requested the first action the GC takes is to stop the world, ie ask, then wait, for all goroutines to return to the scheduler. A single running goroutine can delay the stop the world phase, theoretically indefinitely, if it is performing a CPU intensive operation. 

To solve this problem a check is added for a stop the world flag to the preamble of every function entry allowing the garbage collector to halt running goroutines faster, lowering the overall time for a GC cycle.

The Go 1.2 release notes [[http://golang.org/doc/go1.2#preemption][have more information]] on this feature.

** Integrated network poller

The work that was started by Mikio Hara, Alex Brainman and Dmirty Vyukov in 1.1 integrating the the network polling subsystem directly into the runtime was completed for Windows and the BSD family. All platforms now use the integrated network poller. This has also resolved [[http://golang.org/issue/5596][the `freebsd/amd64`]] regression noted during Go 1.1.

.image day-02-go-1.2-performance-improvements/freebsd-amd64-http.png

** Garbage collector improvements

A large amount of work tool place during the 1.2 cycle to further improve the performance of the garbage collector.

While the garbage collector is not completely precise yet (this work continues in the 1.3 cycle), its precision has improved over Go 1.1, which itself was a major improvement over 1.0.

Improving the precision of the garbage collector means fewer values on the heap are mistaken for pointers. This has the direct result that the heap is smaller. A smaller heap leads to lower garbage collection time overall as well as lowering the memory footprint of Go programs.

Finishing the work of making the garbage collector precise is a major focus of the 1.3 development cycle.

** Faster primitives

In my previous series on Go 1.1 I showed large data sets from the `runtime` package benchmarks. This time around I'm going to focus only on some key improvements.

*** Memmove improvements

For Intel platforms [[https://codereview.appspot.com/9038048][Keith Randall landed]] a change shortly after the 1.2 tree opened that improved small memmove operations, and thus `copy` significantly.

 # linux/amd64
 benchmark                                 old MB/s     new MB/s  speedup
 BenchmarkMemmove32                         1405.39      5462.62    3.89x
 BenchmarkMemmove4K                        22415.16     23127.08    1.03x
 BenchmarkMemmove64K                       18583.10     18477.46    0.99x
 BenchmarkMemmove4M                         5182.82      5171.82    1.00x
 BenchmarkMemmove64M                        5159.03      5170.81    1.00x

 # linux/386
 benchmark                                 old MB/s     new MB/s  speedup
 BenchmarkMemmove32                          400.89       942.76    2.35x
 BenchmarkMemmove4K                         3014.72      3088.95    1.02x
 BenchmarkMemmove64K                        1871.83      1875.65    1.00x
 BenchmarkMemmove4M                          889.91       890.49    1.00x
 BenchmarkMemmove64M                         882.89       888.91    1.01x

*** Faster append

The `append` built in function was improved in Go 1.1 by Rob Pike to reduce its overhead when being called on slices with a small number of elements, which is a common operation. During 1.2 this was improved further by [[https://codereview.appspot.com/12815046/][Rémy Oudompheng]] who moved the append operations into the compiler thus reducing the overhead for all append operations.

.image day-02-go-1.2-performance-improvements/append.png

*** Unified strings and bytes primitives

In Go 1.1 `bytes.IndexByte` and `bytes.Equal` received assembly versions for all three architectures which improved their throughput. In Go 1.2 this was [[https://codereview.appspot.com/12483043][improved further]] by unifying the operation of their counterparts in the `strings` package.

** Http benchmark numbers

.image day-02-go-1.2-performance-improvements/http-amd64.png

** Cypto and compress improvements

One area where Go continues to lag is the performance of its crypto libraries. 

During the cycle Nick Craig-Wood contributed a number of faster crypto primatives for arm (and I'm told more is to come). 

Rémy Oudompheng significantly improved the speed of `crypto/des` and contributed major speedups to `compress/flate` and `compress/bzip2`

* Real world improvements

As Release Candidates started to arrive in September I took some time to brush the cobwebs off [[https://github.com/davecheney/autobench][autobench]] and put out a call for benchmark contributions. Along the way new benchmarks were contributed from external Go libraries which give an important view on the performance improvements Go 1.2 bring to code outside the standard library.

** Megajson performance
.image day-02-go-1.2-performance-improvements/megajson.png
Ben Johnson's [[https://github.com/benbjohnson/megajson][Megajson]] package shows a 15-25% improvement over Go 1.1.2.

** Snappy performance
.image day-02-go-1.2-performance-improvements/snappy.png
Snappy benchmarks show a big improvement on amd64 and arm platforms under Go 1.2. Oddly there is no improvement for 386.

These images are generated by AJ Starks' great [[http://mindchunk.blogspot.com.au/2013/05/visualizing-go-benchmarks-with-benchviz.html][benchviz]] tool.

* Wrapping up

So, does Go 1.2 deliver on the expectation of performance junkies ? Yes. 

A shorter development cycle and fewer low hanging fruit meant that developers had to work harder to find performance gains. For 64 bit Intel platforms the gains appear to be in the 15-20% range for real world code. For the other 32bit platforms, the gains are more modest, in the 10% range.

* Looking forward to the 1.3 development cycle

Planning for the 1.3 cycle has been underway for a month now. Rob Pike opened the discussion on the second of November with [[https://groups.google.com/d/msg/golang-dev/846QFpppXUo/satz-x5kxosJ][this thread]] out of which came a [[http://golang.org/s/go13todo][document]] identifying the major items for this cycle. Russ Cox has also provided a [[http://research.swtch.com/dashboard/Go1.3#all][dashboard]] to track the progress of 1.3.

Dmitry Vyukov has announced a [[https://groups.google.com/forum/#!msg/golang-dev/SvByhCXPwG8/iDyRCaiQVGAJ][performance dashboard]] which will track a slew of measurements for each commit. The dashboard is currently running on a [[http://goperfd.appspot.com/perf][temporary url]] but is expected to be integrated into the [[http://build.golang.org][main CI dashboard]] soon.

There is also a renewed focus on tool chain performance. We picked up a 30% speedup in compilation time in 1.1, but have lost most of that over the 1.2 cycle.

Russ Cox has proposed some wide ranging changes to the linker which will move more work to the compiler, thus becoming parallisable. Russ has published a document with his plans for a [[http://golang.org/s/go13linker][revised linker in 1.3]].

Similarly the size of final Go executables, while never svelte, have been rising steadily for some time now, so work will be done to [[https://code.google.com/p/go/issues/detail?id=6853][understand and reverse]] this trend.

Lastly, although Russ' work in raising the stack segment size to 8kb bought an important performance improvement, it did so at the cost that each goroutine now needs at least 8kb of stack space. For some applications who were happy with the original 4kb stack size, this is overkill, and depending on the sophistication of your operating system's virtual memory subsystem may lead to a larger memory footprint.

To resolve this Russ Cox has proposed moving the runtime to use [[http://golang.org/s/contigstacks][contigious stacks]]. Segmented goroutine stacks will grow and shrink as required without the high cost of straddling the stack segment boundary. Interestingly the Rust project have come to the [[https://mail.mozilla.org/pipermail/rust-dev/2013-November/006550.html][same conclusions]] and are also moving to a contiguous stack model.
 
